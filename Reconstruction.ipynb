{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fda5691-a408-4a76-8450-34713c9af2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data_utils\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import skimage.measure\n",
    "import plyfile\n",
    "import os\n",
    "torch.cuda.empty_cache()\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142ae524-cb4d-4023-9871-f417a037feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  3 20:04:10 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 51%   26C    P8    23W / 350W |      3MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:25:00.0 Off |                  N/A |\n",
      "| 51%   27C    P8    18W / 350W |      3MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 52%   27C    P8    27W / 350W |      3MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 49%   48C    P8    31W / 350W |     13MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 49%   49C    P2   175W / 350W |   1906MiB / 24268MiB |     38%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 51%   51C    P2   181W / 350W |   3730MiB / 24268MiB |     46%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 51%   25C    P8    23W / 350W |      3MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 49%   24C    P8    24W / 350W |      3MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    3   N/A  N/A     45720      G   python                              9MiB |\n",
      "|    4   N/A  N/A     38137      C   ...kym/anaconda3/bin/python3     2641MiB |\n",
      "|    5   N/A  N/A     65495      C   ...kym/anaconda3/bin/python3     3727MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "random.seed(31359)\n",
    "torch.random.manual_seed(31359)\n",
    "np.random.seed(31359)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df944d8f-8f55-4239-89ff-c146c4caa28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of Dataset: 1114\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY_MODELS ='data/SdfSamples/ShapeNetV2/02691156'# 'data/04256520' #'data/SdfSamples/ShapeNetV2/04256520'\n",
    "MODEL_EXTENSION = '.npz'\n",
    "def get_model_files():\n",
    "    for directory, _, files in os.walk(DIRECTORY_MODELS):\n",
    "        for filename in files:\n",
    "            if filename.endswith(MODEL_EXTENSION):\n",
    "                yield  os.path.join(filename)\n",
    "    \n",
    "def get_model_dir():\n",
    "    for directory, _, files in os.walk(DIRECTORY_MODELS):\n",
    "        for filename in files:\n",
    "            if filename.endswith(MODEL_EXTENSION):\n",
    "                yield os.path.join(directory, filename)\n",
    "                \n",
    "files = list(get_model_files())\n",
    "dirs = list(get_model_dir())\n",
    "\n",
    "print(\"the number of Dataset:\", len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007c932a-ac43-42cd-af65-9b52cbedb905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of Dataset(train): 1000\n",
      "the number of Dataset(test): 100\n"
     ]
    }
   ],
   "source": [
    "num_train = 1000\n",
    "num_test = 100\n",
    "# train set!\n",
    "files_dir_train = dirs[:num_train] # /data.../...npz\n",
    "files_npz_train = files[:num_train] # ...npz\n",
    "len(files_npz_train)\n",
    "files_dir_test = dirs[num_train+1:num_train+num_test+1] # /data.../...npz\n",
    "files_npz_test = files[num_train+10:num_train+num_test+10] # ...npz\n",
    "print(\"the number of Dataset(train):\", len(files_npz_train))\n",
    "print(\"the number of Dataset(test):\", len(files_npz_test))# .npz\n",
    "\n",
    "files_npz_test = sorted(files_npz_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439412fb-35e2-4684-8f1c-cc32d9b8c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the DIT github\n",
    "# https://github.com/ZhengZerong/DeepImplicitTemplates\n",
    "\n",
    "#weight initialization \n",
    "def weight_initial(self):\n",
    "    for m in self.modules():\n",
    "        for name, param in m.named_parameters():\n",
    "            #print(name)\n",
    "           # print(param)\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            #print(param)\n",
    "            \n",
    "#output weight initialization\n",
    "def weights_out_init(self):\n",
    "    for m in self.modules():\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.uniform_(param.data, -1e-5, 1e-5)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed5c3cc-f8f3-41a7-92f7-0fe5a9605ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: warped point (from warper) and predicted SDF (from MLP)\n",
    "\n",
    "class DIT(nn.Module):\n",
    "    def __init__(self, mlp_args, lstm_args):\n",
    "        \"\"\"\n",
    "            the entire network consisting of the LSTM and the MLP\n",
    "        \"\"\"\n",
    "        super(DIT, self).__init__()\n",
    "        self.mlp = MLP(**mlp_args)\n",
    "        self.lstm = Warper(**lstm_args)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # get warped points\n",
    "        p_canonical, warping_param, intermediate_xyzs = self.lstm(x)\n",
    "\n",
    "        if self.training:\n",
    "            # get sdf value for each intermediate warping step\n",
    "            sdf_values = []\n",
    "            for points in intermediate_xyzs:#step:\n",
    "                sdf = self.mlp(torch.tensor(points, device = 'cuda'))\n",
    "                sdf_values.append(torch.tensor(sdf, device = 'cuda').squeeze())\n",
    "            return sdf_values, intermediate_xyzs\n",
    "        else:\n",
    "       #     print(\"No Train\")\n",
    "             # only final sdf value\n",
    "            sdf = self.mlp(p_canonical)\n",
    "            #squeeze된 sdf\n",
    "            return sdf, p_canonical\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49fc1a54-12d9-41ae-bda9-f9d2aa7f5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Warper(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            steps,\n",
    "            latent_size,\n",
    "            h_size,\n",
    "            dim,\n",
    "            linee = False\n",
    "    ):\n",
    "        super(Warper, self).__init__()\n",
    "        #latent vector + xyz coordinates\n",
    "        out_len = 6\n",
    "        self.n_feature_channels = latent_size + 3\n",
    "        self.h_size = h_size\n",
    "        self.steps = steps\n",
    "        self.lstm = nn.LSTMCell(input_size=self.n_feature_channels,\n",
    "                                hidden_size=h_size)\n",
    "        lstm_layer = self.lstm\n",
    "        out_len = 6\n",
    "\n",
    "        #weight initial\n",
    "        lstm_layer.apply(weight_initial)\n",
    "        for n, p in lstm_layer.named_parameters():\n",
    "            if \"bias\" in n: # continue\n",
    "                si = p.size(0)\n",
    "                start, end = si // 4, si // 2\n",
    "                p.data[start:end].fill_(1.)\n",
    "\n",
    "        self.out_feature = nn.Linear(h_size, out_len)\n",
    "        #out weight initializer\n",
    "        self.out_feature.apply(weights_out_init)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xyz = input[:, -3:] #change\n",
    "        lat = input[:, :-3] # fix\n",
    "        states = [None]\n",
    "        warped_xyzs = []\n",
    "        warping_p = []\n",
    "\n",
    "        # Step for 8 times\n",
    "        for s in range(self.steps):\n",
    "            cell_st = self.lstm( torch.cat([lat, xyz], dim=1), states[-1]) #Latest state!\n",
    "            rgd = cell_st[0].requires_grad\n",
    "            if rgd:\n",
    "                cell_st[0].register_hook(lambda x: x.clamp(min=-10, max=10))\n",
    "            a = self.out_feature(cell_st[0])\n",
    "            \n",
    "            int_xyz = torch.addcmul(a[:, 3:], (a[:, :3]+1), xyz)\n",
    "                                    #SDF + 1*(1+ w_xyz)*xyz\n",
    "            \n",
    "            if (s+1) % 2 == 0:\n",
    "                warped_xyzs.append(int_xyz)\n",
    "                \n",
    "            states.append(cell_st)\n",
    "            warping_p.append(a)\n",
    "\n",
    "                #중간에 있는 값들!\n",
    "            xyz = int_xyz\n",
    "        return xyz, warping_p, warped_xyzs \n",
    "        #latest xyz, parameter, intermediate xyzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "051ed345-081e-4621-8597-507f7520c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP : SDF Decoder\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layers, wn_layers, weight_norm, dropout_layers, dropout_prob):\n",
    "        \"\"\"\n",
    "            Initialize the MLP that extracts the template SDF\n",
    "        \"\"\"\n",
    "        \n",
    "        # layers: number of layers + size of each layer\n",
    "        # [256, 256, 256, 256, 256] \n",
    "        # => 5 layers with 256 neurons each\n",
    "        \n",
    "        # wn_layers: layer indices in which normalization is used\n",
    "        # [0, 1, 2, 3, 4]\n",
    "        \n",
    "        # weight_norm: bool\n",
    "        # which normalization to use????? TODO\n",
    "        \n",
    "        # dropout_layers: layer indices in which dropout is used\n",
    "        # [0, 1, 2, 3, 4]\n",
    "        \n",
    "        # dropout_prob: probability for dropout\n",
    "        # 0.05\n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.numlayers = len(layers)+1\n",
    "        #print(\"numlayers\", self.numlayers)\n",
    "        \n",
    "        in_dim = 3\n",
    "        out_dim = 1\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(self.numlayers):\n",
    "            #print(i)\n",
    "            # layer input feature count (for first layer: in_dim)\n",
    "            in_features = in_dim if (i == 0) else layers[i-1]\n",
    "            # layer output feature count (for last layer: out_dim)\n",
    "            out_features = out_dim if (i == (len(layers))) else layers[i]\n",
    "            \n",
    "            # fully connected layer\n",
    "            layer = nn.Linear(in_features, out_features)\n",
    "            \n",
    "            modules = [layer]\n",
    "            if i in wn_layers:\n",
    "                # weight normalization layer\n",
    "                if False:  ##########weight_norm: ########## TODO\n",
    "                    layer = nn.utils.weight_norm(layer) # ????????\n",
    "                    modules[0] = layer\n",
    "                else:\n",
    "                    modules.append(nn.LayerNorm(out_features))\n",
    "                    modules.append(nn.BatchNorm1d(out_features))\n",
    "        \n",
    "            # activation (tanh if last layer, else relu)\n",
    "            activation = nn.Tanh() if (i == (len(layers))) else nn.ReLU()\n",
    "            modules.append(activation)\n",
    "            \n",
    "            # dropout\n",
    "            if i in dropout_layers: ### TODO only if training??\n",
    "                modules.append(nn.Dropout(dropout_prob))\n",
    "            \n",
    "\n",
    "            sequential = nn.Sequential(*modules)\n",
    "            self.layers.append(sequential)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "        return x # .squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab6e789-e0db-419f-a604-037c85bf02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from the DeepSDF GitHub\n",
    "#https://github.com/facebookresearch/DeepSDF/blob/48c19b8d49ed5293da4edd7da8c3941444bc5cd7/deep_sdf/data.py\n",
    "\n",
    "repeat = 8\n",
    "save_latvec_only = False #True면 Mesh 파일은 저장 X\n",
    "\n",
    "recon_dir = 'reconstruction_plane/'\n",
    "mesh_dir = 'mesh/'\n",
    "lat_dir = 'latent/'\n",
    "os.path.exists(recon_dir)\n",
    "if not os.path.exists(recon_dir):\n",
    "    os.mkdir(recon_dir)\n",
    "if not os.path.exists(recon_dir+mesh_dir):\n",
    "    os.mkdir(recon_dir+mesh_dir)\n",
    "mesh_dd = recon_dir+mesh_dir\n",
    "lat_dd  = recon_dir+lat_dir\n",
    "if not os.path.exists(recon_dir+lat_dir):\n",
    "    os.mkdir(recon_dir+lat_dir)\n",
    "    \n",
    "       \n",
    "\n",
    "def unpack(data, subsample=None):\n",
    "    if subsample is None:\n",
    "        return data\n",
    "    pos_tensor = data[0]\n",
    "    neg_tensor = data[1]\n",
    "\n",
    "    # split the sample into half\n",
    "    half = int(subsample / 2)\n",
    "\n",
    "    pos_size = pos_tensor.shape[0]\n",
    "    neg_size = neg_tensor.shape[0]\n",
    "\n",
    "    pos_start_ind = random.randint(0, pos_size - half)\n",
    "    sample_pos = pos_tensor[pos_start_ind : (pos_start_ind + half)]\n",
    "\n",
    "    if neg_size <= half:\n",
    "        random_neg = (torch.rand(half) * neg_tensor.shape[0]).long()\n",
    "        sample_neg = torch.index_select(neg_tensor, 0, random_neg)\n",
    "    else:\n",
    "        neg_start_ind = random.randint(0, neg_size - half)\n",
    "        sample_neg = neg_tensor[neg_start_ind : (neg_start_ind + half)]\n",
    "\n",
    "    samples = torch.cat([sample_pos, sample_neg], 0)\n",
    "   # print(\"samples: \",samples)\n",
    "    randidx = torch.randperm(samples.shape[0])\n",
    "    samples = torch.index_select(samples, 0, randidx)\n",
    " #   print(\"samples(OUT): \",samples)\n",
    "    return samples\n",
    "\n",
    "def create_mesh(\n",
    "    decoder, latent_vec, filename, N=256, max_batch=(2**20), offset=None, scale=None, volume_size=2.0\n",
    "    #decoder, latent_vec, filename, N=256, max_batch=(32 ** 3 * 4), offset=None, scale=None, volume_size=2.0\n",
    "):\n",
    "    start = time.time()\n",
    "    ply_filename = filename\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-volume_size/2.0, -volume_size/2.0, -volume_size/2.0]\n",
    "#    voxel_origin = [-1.0,-1.0,-1.0]\n",
    "\n",
    "    voxel_size = volume_size / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() // N) % N\n",
    "    samples[:, 0] = ((overall_index.long() // N) // N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "    samples.requires_grad = False\n",
    "\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n",
    "        \n",
    "        samples[head : min(head + max_batch, num_samples), 3] = (\n",
    "            decode_sdf(decoder, latent_vec, sample_subset)\n",
    "            .squeeze()\n",
    "            .detach()\n",
    "            .cuda()\n",
    "        )\n",
    "        head += max_batch\n",
    "    sdf_values = samples[:, 3]\n",
    "    print(\"sdf_values\", sdf_values.min(), sdf_values.max())\n",
    "    sdf_values = sdf_values.reshape(N, N, N)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    convert_sdf_samples_to_ply(\n",
    "        sdf_values.data.cuda(),\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        ply_filename + \".ply\",\n",
    "        offset,\n",
    "        scale,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def decode_sdf(decoder, latent_vector, queries):\n",
    "    num_samples = queries.shape[0]\n",
    "\n",
    "    if latent_vector is None:\n",
    "        inputs = queries\n",
    "        sdf = decoder(inputs)[:, :1]\n",
    "    else:\n",
    "        try:\n",
    "            latent_repeat = latent_vector.expand(num_samples, -1)\n",
    "            inputs = torch.cat([latent_repeat, queries], 1)\n",
    "            with torch.no_grad():\n",
    "                sdf, p_can = decoder(inputs)\n",
    "\n",
    "        except:\n",
    "            raise RuntimeError(\"Failed to decode SDF\")\n",
    "\n",
    "    return sdf\n",
    "\n",
    "def convert_sdf_samples_to_ply(\n",
    "    input_3d_sdf_array,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    ply_filename_out,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .ply\n",
    "\n",
    "    :param input_3d_sdf_array: a float array of shape (n,n,n)\n",
    "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
    "    :voxel_size: float, the size of the voxels\n",
    "    :ply_filename_out: string, path of the filename to save to\n",
    "\n",
    "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if isinstance(input_3d_sdf_array, torch.Tensor):\n",
    "        numpy_3d_sdf_tensor = input_3d_sdf_array.cpu().numpy()\n",
    "    elif isinstance(input_3d_sdf_array, np.ndarray):\n",
    "        numpy_3d_sdf_tensor = input_3d_sdf_array\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    print(\"numpy_3d_sdf_tensor\",np.shape(numpy_3d_sdf_tensor)) #256 256 256\n",
    "    print(\"numpy_3d_sdf_tensor\",numpy_3d_sdf_tensor.min())\n",
    "    print(\"numpy_3d_sdf_tensor\",numpy_3d_sdf_tensor.max())\n",
    "    \n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3,method ='lewiner'\n",
    "    )\n",
    "\n",
    "    # transform from voxel coordinates to camera coordinates\n",
    "    # note x and y are flipped in the output of marching_cubes\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    # apply additional offset and scale\n",
    "    if scale is not None:\n",
    "        mesh_points = mesh_points / scale\n",
    "    if offset is not None:\n",
    "        mesh_points = mesh_points - offset\n",
    "\n",
    "    # try writing to the ply file\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces])\n",
    "    print(\"saving mesh to %s\" % (ply_filename_out))\n",
    "    ply_data.write(ply_filename_out)\n",
    "\n",
    "    print(\n",
    "        \"converting to ply format and writing to file took {} s\".format(\n",
    "            time.time() - start_time\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de408d6-1647-435c-804d-97f7d60fa490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(\n",
    "    decoder,\n",
    "    num_iterations,\n",
    "    latent_size,\n",
    "    test_sdf,\n",
    "    stat,\n",
    "    clamp_dist,\n",
    "    num_samples=8000,\n",
    "    lr1=5e-4,\n",
    "    l2reg=False,\n",
    "):\n",
    "    mul_d = 10\n",
    "  #  decoder.train()\n",
    "    if type(stat) == type(0.1):\n",
    "        latent = torch.ones(1, latent_size).normal_(mean=0, std=stat).cuda()\n",
    "    else:\n",
    "        latent = torch.normal(stat[0].detach(), stat[1].detach()).cuda() #?\n",
    "    #요것이 Latent\n",
    "    latent.requires_grad = True\n",
    "    #Latent Code Optimize!\n",
    "    optimizer = torch.optim.Adam([latent], lr=lr1)\n",
    "\n",
    "    loss_num = 0\n",
    "    loss_l1 = torch.nn.L1Loss()\n",
    "\n",
    "    decoder.eval()\n",
    "    for e in range(num_iterations):\n",
    "        sdf_data = unpack(test_sdf, num_samples).cuda()\n",
    "        xyz = sdf_data[:, 0:3]\n",
    "        sdf_gt = sdf_data[:, 3].unsqueeze(1)\n",
    "        #SDF값\n",
    "        sdf_gt = torch.clamp(sdf_gt, -clamp_dist, clamp_dist)\n",
    "    #    print(\"sdf_gt:\", min(sdf_gt), max(sdf_gt))\n",
    " \n",
    "       # adjust_learning_rate(lr, optimizer, e, mul_d, adjust_lr_every)\n",
    "        lr = lr1 * ((1 / mul_d) ** (num_iterations //  int(num_iterations / 2)))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        latent_inputs = latent.expand(num_samples, -1)\n",
    "        #latent와 xyz를 concat\n",
    "        inputs = torch.cat([latent_inputs, xyz], 1).cuda()\n",
    "        pred_sdf,_ = decoder(inputs)\n",
    "        \n",
    "        pred_sdf = torch.clamp(pred_sdf, -clamp_dist, clamp_dist)\n",
    "    #    print(\"pred_sdf:\", (pred_sdf))#, max(pred_sdf))\n",
    "    \n",
    "        #SDF 기준으로 loss값 설정\n",
    "        loss = loss_l1(pred_sdf, sdf_gt)\n",
    "        if l2reg:\n",
    "            loss += 1e-4 * torch.mean(latent.pow(2))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_num = loss.item()\n",
    "\n",
    "        if e % 50 == 0:\n",
    "            print(\"num_iterations:\",e)\n",
    "\n",
    "            print(\"loss_num: \",loss_num)\n",
    "\n",
    "\n",
    "    return loss_num, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9375a998-08e6-418d-b69a-92e671f6c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Load\n",
    "\n",
    "# initialize Network\n",
    "from easydict.easydict import EasyDict as edict\n",
    "#from easydict import EasyDict as edict\n",
    "\n",
    "lstm_args = edict()\n",
    "lstm_args.steps = 8\n",
    "lstm_args.latent_size = 256\n",
    "lstm_args.h_size = 512\n",
    "lstm_args.dim = [512, 64]\n",
    "\n",
    "#lat_vecs = torch.nn.Embedding(len(sdf_loader), lstm_args.latent_size, max_norm=1)\n",
    "\n",
    "mlp_args = edict()\n",
    "mlp_args.layers = [256,256,256,256,256]\n",
    "mlp_args.wn_layers = [0,1,2,3,4]\n",
    "mlp_args.weight_norm = True\n",
    "mlp_args.dropout_layers =[0,1,2,3,4]\n",
    "mlp_args.dropout_prob = 0.05\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "weights = torch.load(\"./weights_plane/weights_190.pt\", map_location=device)\n",
    "decoder = DIT(mlp_args, lstm_args)\n",
    "decoder.load_state_dict(weights)\n",
    "#print(model)\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "#print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c2b388-b3f8-44b4-a00d-90a8f18d5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  10c7cdfdffe2243b88a89a28f04ce622.npz\n",
      "Reconstruction:  10c7cdfdffe2243b88a89a28f04ce622.npz\n",
      "Latent_Filename:  reconstruction_plane/latent/10c7cdfdffe2243b88a89a28f04ce622.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.0035911465529352427\n",
      "num_iterations: 50\n",
      "loss_num:  0.002941771177574992\n",
      "num_iterations: 100\n",
      "loss_num:  0.0035904415417462587\n",
      "num_iterations: 150\n",
      "loss_num:  0.0029714677948504686\n",
      "num_iterations: 200\n",
      "loss_num:  0.002918465528637171\n",
      "num_iterations: 250\n",
      "loss_num:  0.002896347548812628\n",
      "num_iterations: 300\n",
      "loss_num:  0.002793213352560997\n",
      "num_iterations: 350\n",
      "loss_num:  0.002919080201536417\n",
      "num_iterations: 400\n",
      "loss_num:  0.002856816630810499\n",
      "num_iterations: 450\n",
      "loss_num:  0.0028844159096479416\n",
      "num_iterations: 500\n",
      "loss_num:  0.0030602230690419674\n",
      "num_iterations: 550\n",
      "loss_num:  0.0027297402266412973\n",
      "num_iterations: 600\n",
      "loss_num:  0.0032231712248176336\n",
      "num_iterations: 650\n",
      "loss_num:  0.003112227190285921\n",
      "num_iterations: 700\n",
      "loss_num:  0.0028347845654934645\n",
      "num_iterations: 750\n",
      "loss_num:  0.0028994870372116566\n",
      "Current Error Avg:  0.0026718666777014732\n",
      "Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab1_kym/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf_values tensor(-0.4417) tensor(1.0000)\n",
      "numpy_3d_sdf_tensor (256, 256, 256)\n",
      "numpy_3d_sdf_tensor -0.44166005\n",
      "numpy_3d_sdf_tensor 0.99999964\n",
      "saving mesh to reconstruction_plane/mesh/10c7cdfdffe2243b88a89a28f04ce622.ply\n",
      "converting to ply format and writing to file took 2.9664082527160645 s\n",
      "Reconstruction:  10c7cdfdffe2243b88a89a28f04ce622.npz\n",
      "Latent_Filename:  reconstruction_plane/latent/10c7cdfdffe2243b88a89a28f04ce622.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.0033517279662191868\n",
      "num_iterations: 50\n",
      "loss_num:  0.0029340239707380533\n",
      "num_iterations: 100\n",
      "loss_num:  0.002954560099169612\n",
      "num_iterations: 150\n",
      "loss_num:  0.0030269958078861237\n",
      "num_iterations: 200\n",
      "loss_num:  0.003178349230438471\n",
      "num_iterations: 250\n",
      "loss_num:  0.002760005882009864\n",
      "num_iterations: 300\n",
      "loss_num:  0.003002570243552327\n",
      "num_iterations: 350\n",
      "loss_num:  0.0031419110018759966\n",
      "num_iterations: 400\n",
      "loss_num:  0.003018223447725177\n",
      "num_iterations: 450\n",
      "loss_num:  0.0030272745061665773\n",
      "num_iterations: 500\n",
      "loss_num:  0.002700683893635869\n",
      "num_iterations: 550\n",
      "loss_num:  0.002659217221662402\n",
      "num_iterations: 600\n",
      "loss_num:  0.002884199842810631\n",
      "num_iterations: 650\n",
      "loss_num:  0.002835765713825822\n",
      "num_iterations: 700\n",
      "loss_num:  0.002791566774249077\n",
      "num_iterations: 750\n",
      "loss_num:  0.0026530541945248842\n",
      "Current Error Avg:  0.0025945124216377735\n",
      "Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?\n",
      "sdf_values tensor(-0.4417) tensor(1.0000)\n",
      "numpy_3d_sdf_tensor (256, 256, 256)\n",
      "numpy_3d_sdf_tensor -0.44172552\n",
      "numpy_3d_sdf_tensor 0.99999964\n",
      "saving mesh to reconstruction_plane/mesh/10c7cdfdffe2243b88a89a28f04ce622.ply\n",
      "converting to ply format and writing to file took 3.0091774463653564 s\n",
      "Reconstruction:  10c7cdfdffe2243b88a89a28f04ce622.npz\n",
      "Latent_Filename:  reconstruction_plane/latent/10c7cdfdffe2243b88a89a28f04ce622.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.003297470510005951\n",
      "num_iterations: 50\n",
      "loss_num:  0.0029646798502653837\n",
      "num_iterations: 100\n",
      "loss_num:  0.0029605445452034473\n",
      "num_iterations: 150\n",
      "loss_num:  0.0032651652581989765\n",
      "num_iterations: 200\n",
      "loss_num:  0.003321658819913864\n",
      "num_iterations: 250\n",
      "loss_num:  0.003116111969575286\n",
      "num_iterations: 300\n",
      "loss_num:  0.003199443919584155\n",
      "num_iterations: 350\n",
      "loss_num:  0.003091283841058612\n",
      "num_iterations: 400\n",
      "loss_num:  0.002876627491787076\n",
      "num_iterations: 450\n",
      "loss_num:  0.0031358629930764437\n",
      "num_iterations: 500\n",
      "loss_num:  0.0024850890040397644\n",
      "num_iterations: 550\n",
      "loss_num:  0.003118449356406927\n",
      "num_iterations: 600\n",
      "loss_num:  0.00302664702758193\n",
      "num_iterations: 650\n",
      "loss_num:  0.0028824442997574806\n",
      "num_iterations: 700\n",
      "loss_num:  0.002967255422845483\n",
      "num_iterations: 750\n",
      "loss_num:  0.002833876060321927\n",
      "Current Error Avg:  0.0026465950068086386\n",
      "Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?\n",
      "sdf_values tensor(-0.4417) tensor(1.0000)\n",
      "numpy_3d_sdf_tensor (256, 256, 256)\n",
      "numpy_3d_sdf_tensor -0.44165513\n",
      "numpy_3d_sdf_tensor 0.99999964\n",
      "saving mesh to reconstruction_plane/mesh/10c7cdfdffe2243b88a89a28f04ce622.ply\n",
      "converting to ply format and writing to file took 2.803138256072998 s\n",
      "Reconstruction:  10c7cdfdffe2243b88a89a28f04ce622.npz\n",
      "Latent_Filename:  reconstruction_plane/latent/10c7cdfdffe2243b88a89a28f04ce622.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.0030192506965249777\n",
      "num_iterations: 50\n",
      "loss_num:  0.0031880848109722137\n",
      "num_iterations: 100\n",
      "loss_num:  0.0028674746863543987\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-005e61c98fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"학습된 code를 활용하지 않는다는 의미!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             err, latent = reconstruct(\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-f5b572f474cc>\u001b[0m in \u001b[0;36mreconstruct\u001b[0;34m(decoder, num_iterations, latent_size, test_sdf, stat, clamp_dist, num_samples, lr1, l2reg)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#latent와 xyz를 concat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatent_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mpred_sdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mpred_sdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mclamp_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclamp_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-49b0dc885185>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# get warped points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mp_canonical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarping_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_xyzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-74bff264f817>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Step for 8 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mcell_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Latest state!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mrgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_st\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrgd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         return _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = 800\n",
    "latent_size = 256\n",
    "num_samples=8000\n",
    "stat = 0.01\n",
    "clamp_dist = 0.1\n",
    "lr=5e-3\n",
    "l2reg=True\n",
    "resolution = 256\n",
    "use_octree = False\n",
    "\n",
    "for ii, npz in enumerate(files_npz_test):\n",
    "#    print(npz)\n",
    "    if \"npz\" not in npz:\n",
    "        continue\n",
    "    # files_dir_test #dirs\n",
    "    print(\"Loading: \",npz)\n",
    "#    DIRECTORY_MODELS\n",
    "    npz1 = np.load(DIRECTORY_MODELS+ '/'+ npz)\n",
    "    pos_tensor = torch.from_numpy(npz1[\"pos\"])\n",
    "    neg_tensor = torch.from_numpy(npz1[\"neg\"])\n",
    "    \n",
    "    data_sdf = [pos_tensor, neg_tensor]\n",
    "\n",
    "    for k in range(repeat):\n",
    "\n",
    "        mesh_filename = os.path.join(mesh_dd, npz[:-4])\n",
    "        latent_filename = os.path.join(lat_dd, npz[:-4] + \".pth\")\n",
    "\n",
    "        print(\"Reconstruction: \", npz)\n",
    "        \n",
    "        data_sdf[0] = data_sdf[0][torch.randperm(data_sdf[0].shape[0])]\n",
    "        data_sdf[1] = data_sdf[1][torch.randperm(data_sdf[1].shape[0])]\n",
    "\n",
    "        start = time.time()\n",
    "        print(\"Latent_Filename: \", latent_filename)\n",
    "\n",
    "        if not os.path.isfile(latent_filename):\n",
    "            print(\"학습된 code를 활용하지 않는다는 의미!\")\n",
    "            loss_sum = 0\n",
    "            err, latent = reconstruct(\n",
    "                decoder,\n",
    "                int(iterations),\n",
    "                latent_size,\n",
    "                data_sdf,\n",
    "                0.01,  \n",
    "                0.1,\n",
    "                num_samples=8000,\n",
    "                lr1=5e-3,\n",
    "                l2reg=True,\n",
    "            )\n",
    "            loss_sum += err\n",
    "            print(\"Current Error Avg: \", loss_sum/(ii+1))\n",
    "            \n",
    "        if not save_latvec_only:\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                #octree를 사용한다.\n",
    "                if use_octree:\n",
    "                    create_mesh_octree(\n",
    "                        decoder, latent, mesh_filename, N=resolution, max_batch=int(2 ** 17), volume_size = 0.5, #volume_size = 0.1 > 그냥 네모가 작아질 뿐\n",
    "                        clamp_func=clamping_function\n",
    "                    )\n",
    "                #Octree를 사용하지 않는다.\n",
    "                else:\n",
    "                    print('Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?')\n",
    "                    create_mesh(\n",
    "                        decoder, latent, mesh_filename, N=resolution, max_batch=int(2 ** 17),\n",
    "                    )                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3ce3310-62f3-4a8a-858c-af4a8721113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10c7cdfdffe2243b88a89a28f04ce622.npz',\n",
       " '17ac3afd54143b797172a40a4ca640fe.npz',\n",
       " '17ad3ab1b1d12a7db26dc8ec64d633df.npz',\n",
       " '17c86b46990b54b65578b8865797aa0.npz',\n",
       " '18d123aaef6b911954eefcdc602d4520.npz',\n",
       " '18e86ba0172154f3bc0909d98a1ff2b4.npz',\n",
       " '1bba3fb413b93890947bbeb9022263b8.npz',\n",
       " '1beb0776148870d4c511571426f8b16d.npz',\n",
       " '1c93b0eb9c313f5d9a6e43b878d5b335.npz',\n",
       " '1d09583e9236b8d149d860a48be37092.npz',\n",
       " '1d0c128592385580e2129f6359ec27e3.npz',\n",
       " '1d5708929a4ae05842d1180c659735fe.npz',\n",
       " '1eb3af39d93c8bf2ddea2f4a0e0f0d2e.npz',\n",
       " '1fc2625479e798b11944f01d3ab2091b.npz',\n",
       " '24bdf389877fb7f21b1f694e36340ebb.npz',\n",
       " '24c2cc372c63603137678474be485ca.npz',\n",
       " '24d4c063f7a361bacbc6ff5546f4ec42.npz',\n",
       " '29b92db18649b64e959a8a7d5a8a5077.npz',\n",
       " '2a06adfb446c85c9f9d3f977c7090b2a.npz',\n",
       " '2a2caad9e540dcc687bf26680c510802.npz',\n",
       " '2a801b1918ef23f1121ca0b13e917b22.npz',\n",
       " '2af04ef09d49221b85e5214b0d6a7.npz',\n",
       " '2bc0d99cba39f7adbbf3143b1cb6076a.npz',\n",
       " '2c1f66380af03e4c5d1df55cbe0874aa.npz',\n",
       " '2d43c1430df8194ace5721ccacba16.npz',\n",
       " '2d4a57a467307d675e9e2656aff7dd5b.npz',\n",
       " '33d955301966e4215ebedace13b486c4.npz',\n",
       " '34ddff243ac3783521b85e5214b0d6a7.npz',\n",
       " '38a8e07ed9b0da99fa7918e5874b2c16.npz',\n",
       " '39d7e8e001e0234e8f721bc8b8155d7.npz',\n",
       " '3a18489f9615a350e768735f27170bc4.npz',\n",
       " '3a3827f1a76c5230e24527abcb488f31.npz',\n",
       " '3a82056ea319a442f64801ad2940cdd5.npz',\n",
       " '3b2a19d782234467f9cc1fc25372199f.npz',\n",
       " '3c80dde1fb615ff5ca8607f540cc62ba.npz',\n",
       " '3c9d577c78dcc3904c3a35cee92bb95b.npz',\n",
       " '3cab1ffcff8b84cbcad035c2ab458.npz',\n",
       " '3cb63efff711cfc035fc197bbabcd5bd.npz',\n",
       " '3fd97395c1d1479b35cfde72d9f6a4cf.npz',\n",
       " '3fe365251b54087af0478431b5ad57db.npz',\n",
       " '40c730231c4da8f33c3bcafb5ffed4c0.npz',\n",
       " '43abe330362164e99be82ec29531a70f.npz',\n",
       " '43c5f85e9a10071cb1bb46d2556ba67d.npz',\n",
       " '46c259e87609c54fafc0cc47720c0ef4.npz',\n",
       " '46d4d453ceac2f5c3c3b254d8683a766.npz',\n",
       " '47d677bf1dec3dca82cea33798fcd6b6.npz',\n",
       " '48d03ffabd0399f4303510f9a56d94fe.npz',\n",
       " '4a27a6276e748777bc0909d98a1ff2b4.npz',\n",
       " '4a300ea7cbe3ae58a42c49797afd1f5c.npz',\n",
       " '4a552066ae1da546cc34b900bb2492e.npz',\n",
       " '4b4fd540cab0cdf3f38bce64a8733419.npz',\n",
       " '4bd5f77521e76e6a2e690fa6dfd5d610.npz',\n",
       " '4bf2c942aafb4a2cbd46d022fd7d80aa.npz',\n",
       " '4bfa5d948d9ca7ab7c5f0032facde6fe.npz',\n",
       " '4c008f39378be18bc0909d98a1ff2b4.npz',\n",
       " '4d50ff789e84e70e54eefcdc602d4520.npz',\n",
       " '4eced94670d10b35e856faf938562bd0.npz',\n",
       " '4f1fb7c062c50fb15a2c5766752aea65.npz',\n",
       " '4f9b12d07dce21ac9d93a50cb0355558.npz',\n",
       " '4fb69651d04e010554eefcdc602d4520.npz',\n",
       " '5c63ad3688c623b1a787d03c28977672.npz',\n",
       " '5d925e4748bb4ad155050237670e0ad2.npz',\n",
       " '5da145252e095024ee738cc95b5ae8e.npz',\n",
       " '5e31a194b02a286df8c6d04d97f8cf7.npz',\n",
       " '6ad89740605331aef5f09964a6a1f97.npz',\n",
       " '6ba7cad8fa7301f9c1ca96a73599ca7e.npz',\n",
       " '6bfee98d2078c3c4ca8607f540cc62ba.npz',\n",
       " '6cd3028fe03d04fec6f6da58b133bae0.npz',\n",
       " '6cdc9acb022b2d7d98aeb62a3dfc01d8.npz',\n",
       " '6cf339eb8c950ac5d556fc099c90ab45.npz',\n",
       " '6d0b546bb6256eb5e66cabd11ba41eae.npz',\n",
       " '6d93492543d1087eb87697d3904b168b.npz',\n",
       " '6dedeb5b87ee318b2154ead1f7ab03aa.npz',\n",
       " '6ea4e68428cba49f68557927e45c29cd.npz',\n",
       " '6eb12144093da25e816e98a113f4d393.npz',\n",
       " '6ed172205a9805b8dd9eb6c0ee8316a3.npz',\n",
       " '6f96517661cf1b6799ed03445864bd37.npz',\n",
       " '6feb039c710277aabd10f71f04d299c.npz',\n",
       " '7a1954799b5fbb438fc2d09ac4aa4e78.npz',\n",
       " '7a97d3dadc608b4350f01eb2b12b0a8.npz',\n",
       " '7bd43965f17c25377209009cfb89d4bd.npz',\n",
       " '7c67e8cce3f3eb3c89ba278a735b3c5a.npz',\n",
       " '7e52ac52a2eb74ac26360e1e29a956c7.npz',\n",
       " '7ea57db538494a2fc1ccec171a275967.npz',\n",
       " '7ecb807e2270606619ba010ddb4974fe.npz',\n",
       " '7ee59463dc17ac6e3e3f3c9608255377.npz',\n",
       " '7f1eaf37fb4e24de82cea33798fcd6b6.npz',\n",
       " '7f6af37cd64377e1cabcecce1c335df1.npz',\n",
       " '8af46946b9b2b3aacf0820a704ed425d.npz',\n",
       " '8bde5a00c3caf9771d03b466c72ce41.npz',\n",
       " '8ef4637cb349584420c6a28228acb628.npz',\n",
       " '8f39d2dbb98bce6057b643a522b3d830.npz',\n",
       " '8fc553e3a88b7ad54e461d462a3ccbc4.npz',\n",
       " '9bf3c126d5918c41f5c7319b71bdce6e.npz',\n",
       " '9c7395d87c59aa54a79f2ed56427c6e6.npz',\n",
       " '9c9d6469ecdfc54fc2a9d7232db0ed61.npz',\n",
       " '9cda097e69ef82beace5721ccacba16.npz',\n",
       " '9dbab9e46b372e837645a27090729af6.npz',\n",
       " '9e30fc9f2d9ae56e3ec83bd6bef75c92.npz',\n",
       " '9f75309b9744f1b54eefcdc602d4520.npz']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_npz_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3bb26-cfa7-4f4d-afd2-7c66473dae0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8df61-5387-4053-b8aa-5f2a923320d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f13f3-2741-4484-afb8-aa9f96eae5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adc62b-b55a-40e8-a76b-2d9593cae656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

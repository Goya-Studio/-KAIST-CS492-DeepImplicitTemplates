{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fda5691-a408-4a76-8450-34713c9af2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data_utils\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import skimage.measure\n",
    "import plyfile\n",
    "import os\n",
    "torch.cuda.empty_cache()\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "142ae524-cb4d-4023-9871-f417a037feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  6 10:49:09 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 52%   26C    P8    23W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:25:00.0 Off |                  N/A |\n",
      "| 52%   26C    P8    18W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 52%   26C    P8    28W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 48%   26C    P8    30W / 350W |   1724MiB / 24268MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 52%   25C    P8    22W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 52%   26C    P8    21W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 52%   25C    P8    23W / 350W |      3MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 49%   24C    P8    23W / 350W |      1MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    3   N/A  N/A     22105      C   ...kym/anaconda3/bin/python3     1721MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "random.seed(31359)\n",
    "torch.random.manual_seed(31359)\n",
    "np.random.seed(31359)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df944d8f-8f55-4239-89ff-c146c4caa28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of Dataset: 8\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY_MODELS = 'Dataset/04256520/'  # 04256520: Sofa\n",
    "#DIRECTORY_MODELS = 'Dataset/02691156' # 02691156 : Plane\n",
    "#DIRECTORY_MODELS = 'Dataset/04379243' # 04379243: Table\n",
    "\n",
    "MODEL_EXTENSION = '.npz'\n",
    "def get_model_files():\n",
    "    for directory, _, files in os.walk(DIRECTORY_MODELS):\n",
    "        for filename in files:\n",
    "            if filename.endswith(MODEL_EXTENSION):\n",
    "                yield  os.path.join(filename)\n",
    "    \n",
    "def get_model_dir():\n",
    "    for directory, _, files in os.walk(DIRECTORY_MODELS):\n",
    "        for filename in files:\n",
    "            if filename.endswith(MODEL_EXTENSION):\n",
    "                yield os.path.join(directory, filename)\n",
    "                \n",
    "files = list(get_model_files())\n",
    "dirs = list(get_model_dir())\n",
    "\n",
    "print(\"the number of Dataset:\", len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "007c932a-ac43-42cd-af65-9b52cbedb905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of Dataset(train): 0\n",
      "the number of Dataset(test): 8\n"
     ]
    }
   ],
   "source": [
    "num_train = 1000\n",
    "num_test = 100\n",
    "# train set!\n",
    "files_dir_test = dirs[:num_test] # /data.../...npz\n",
    "files_npz_test = files[:num_test] # ...npz\n",
    "len(files_npz_train)\n",
    "files_dir_train = dirs[num_test+1:num_train+num_test+1] # /data.../...npz\n",
    "files_npz_train = files[num_test+10:num_train+num_test+10] # ...npz\n",
    "print(\"the number of Dataset(train):\", len(files_npz_train))\n",
    "print(\"the number of Dataset(test):\", len(files_npz_test))# .npz\n",
    "\n",
    "files_npz_test = sorted(files_npz_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "439412fb-35e2-4684-8f1c-cc32d9b8c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the DIT github\n",
    "# https://github.com/ZhengZerong/DeepImplicitTemplates\n",
    "\n",
    "#weight initialization \n",
    "def weight_initial(self):\n",
    "    for m in self.modules():\n",
    "        for name, param in m.named_parameters():\n",
    "            #print(name)\n",
    "           # print(param)\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            #print(param)\n",
    "            \n",
    "#output weight initialization\n",
    "def weights_out_init(self):\n",
    "    for m in self.modules():\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.uniform_(param.data, -1e-5, 1e-5)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ed5c3cc-f8f3-41a7-92f7-0fe5a9605ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: warped point (from warper) and predicted SDF (from MLP)\n",
    "\n",
    "class DIT(nn.Module):\n",
    "    def __init__(self, mlp_args, lstm_args):\n",
    "        \"\"\"\n",
    "            the entire network consisting of the LSTM and the MLP\n",
    "        \"\"\"\n",
    "        super(DIT, self).__init__()\n",
    "        self.mlp = MLP(**mlp_args)\n",
    "        self.lstm = Warper(**lstm_args)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # get warped points\n",
    "        p_canonical, warping_param, intermediate_xyzs = self.lstm(x)\n",
    "\n",
    "        if self.training:\n",
    "            # get sdf value for each intermediate warping step\n",
    "            sdf_values = []\n",
    "            for points in intermediate_xyzs:#step:\n",
    "                sdf = self.mlp(torch.tensor(points, device = 'cuda'))\n",
    "                sdf_values.append(torch.tensor(sdf, device = 'cuda').squeeze())\n",
    "            return sdf_values, intermediate_xyzs\n",
    "        else:\n",
    "       #     print(\"No Train\")\n",
    "             # only final sdf value\n",
    "            sdf = self.mlp(p_canonical)\n",
    "            #squeeze된 sdf\n",
    "            return sdf, p_canonical\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49fc1a54-12d9-41ae-bda9-f9d2aa7f5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Warper(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            steps,\n",
    "            latent_size,\n",
    "            h_size,\n",
    "            dim,\n",
    "            linee = False\n",
    "    ):\n",
    "        super(Warper, self).__init__()\n",
    "        #latent vector + xyz coordinates\n",
    "        out_len = 6\n",
    "        self.n_feature_channels = latent_size + 3\n",
    "        self.h_size = h_size\n",
    "        self.steps = steps\n",
    "        self.lstm = nn.LSTMCell(input_size=self.n_feature_channels,\n",
    "                                hidden_size=h_size)\n",
    "        lstm_layer = self.lstm\n",
    "        out_len = 6\n",
    "\n",
    "        #weight initial\n",
    "        lstm_layer.apply(weight_initial)\n",
    "        for n, p in lstm_layer.named_parameters():\n",
    "            if \"bias\" in n: # continue\n",
    "                si = p.size(0)\n",
    "                start, end = si // 4, si // 2\n",
    "                p.data[start:end].fill_(1.)\n",
    "\n",
    "        self.out_feature = nn.Linear(h_size, out_len)\n",
    "        #out weight initializer\n",
    "        self.out_feature.apply(weights_out_init)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xyz = input[:, -3:] #change\n",
    "        lat = input[:, :-3] # fix\n",
    "        states = [None]\n",
    "        warped_xyzs = []\n",
    "        warping_p = []\n",
    "\n",
    "        # Step for 8 times\n",
    "        for s in range(self.steps):\n",
    "            cell_st = self.lstm( torch.cat([lat, xyz], dim=1), states[-1]) #Latest state!\n",
    "            rgd = cell_st[0].requires_grad\n",
    "            if rgd:\n",
    "                cell_st[0].register_hook(lambda x: x.clamp(min=-10, max=10))\n",
    "            a = self.out_feature(cell_st[0])\n",
    "            \n",
    "            int_xyz = torch.addcmul(a[:, 3:], (a[:, :3]+1), xyz)\n",
    "                                    #SDF + 1*(1+ w_xyz)*xyz\n",
    "            \n",
    "            if (s+1) % 2 == 0:\n",
    "                warped_xyzs.append(int_xyz)\n",
    "                \n",
    "            states.append(cell_st)\n",
    "            warping_p.append(a)\n",
    "\n",
    "                #중간에 있는 값들!\n",
    "            xyz = int_xyz\n",
    "        return xyz, warping_p, warped_xyzs \n",
    "        #latest xyz, parameter, intermediate xyzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "051ed345-081e-4621-8597-507f7520c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP : SDF Decoder\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layers, wn_layers, weight_norm, dropout_layers, dropout_prob):\n",
    "        \"\"\"\n",
    "            Initialize the MLP that extracts the template SDF\n",
    "        \"\"\"\n",
    "        \n",
    "        # layers: number of layers + size of each layer\n",
    "        # [256, 256, 256, 256, 256] \n",
    "        # => 5 layers with 256 neurons each\n",
    "        \n",
    "        # wn_layers: layer indices in which normalization is used\n",
    "        # [0, 1, 2, 3, 4]\n",
    "        \n",
    "        # weight_norm: bool\n",
    "        # which normalization to use????? TODO\n",
    "        \n",
    "        # dropout_layers: layer indices in which dropout is used\n",
    "        # [0, 1, 2, 3, 4]\n",
    "        \n",
    "        # dropout_prob: probability for dropout\n",
    "        # 0.05\n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.numlayers = len(layers)+1\n",
    "        #print(\"numlayers\", self.numlayers)\n",
    "        \n",
    "        in_dim = 3\n",
    "        out_dim = 1\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(self.numlayers):\n",
    "            #print(i)\n",
    "            # layer input feature count (for first layer: in_dim)\n",
    "            in_features = in_dim if (i == 0) else layers[i-1]\n",
    "            # layer output feature count (for last layer: out_dim)\n",
    "            out_features = out_dim if (i == (len(layers))) else layers[i]\n",
    "            \n",
    "            # fully connected layer\n",
    "            layer = nn.Linear(in_features, out_features)\n",
    "            \n",
    "            modules = [layer]\n",
    "            if i in wn_layers:\n",
    "                # weight normalization layer\n",
    "                if False:  ##########weight_norm: ########## TODO\n",
    "                    layer = nn.utils.weight_norm(layer) # ????????\n",
    "                    modules[0] = layer\n",
    "                else:\n",
    "                    modules.append(nn.LayerNorm(out_features))\n",
    "                    modules.append(nn.BatchNorm1d(out_features))\n",
    "        \n",
    "            # activation (tanh if last layer, else relu)\n",
    "            activation = nn.Tanh() if (i == (len(layers))) else nn.ReLU()\n",
    "            modules.append(activation)\n",
    "            \n",
    "            # dropout\n",
    "            if i in dropout_layers: ### TODO only if training??\n",
    "                modules.append(nn.Dropout(dropout_prob))\n",
    "            \n",
    "\n",
    "            sequential = nn.Sequential(*modules)\n",
    "            self.layers.append(sequential)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "        return x # .squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ab6e789-e0db-419f-a604-037c85bf02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from the DeepSDF GitHub\n",
    "#https://github.com/facebookresearch/DeepSDF/blob/48c19b8d49ed5293da4edd7da8c3941444bc5cd7/deep_sdf/data.py\n",
    "\n",
    "repeat = 1\n",
    "save_latvec_only = False #True면 Mesh 파일은 저장 X\n",
    "\n",
    "rec_dir = 'reconstruction/'\n",
    "data = DIRECTORY_MODELS.split('/')\n",
    "recon_dir = rec_dir + data[1]\n",
    "mesh_dir = '/mesh/'\n",
    "lat_dir = '/latent/'\n",
    "\n",
    "\n",
    "if data[1] == \"04256520\":\n",
    "    class1 = 'weights_sofa'\n",
    "elif data[1] == \"04379243\":\n",
    "    class1 = 'weights_table'\n",
    "\n",
    "elif data[1] == \"02691156\":\n",
    "    class1 = 'weights_plane'\n",
    "    \n",
    "    \n",
    "if not os.path.exists(rec_dir):\n",
    "    os.mkdir(rec_dir)\n",
    "if not os.path.exists(recon_dir):\n",
    "    os.mkdir(recon_dir)\n",
    "if not os.path.exists(recon_dir+mesh_dir):\n",
    "    os.mkdir(recon_dir+mesh_dir)\n",
    "mesh_dd = recon_dir+mesh_dir\n",
    "lat_dd  = recon_dir+lat_dir\n",
    "if not os.path.exists(recon_dir+lat_dir):\n",
    "    os.mkdir(recon_dir+lat_dir)\n",
    "    \n",
    "       \n",
    "\n",
    "def unpack(data, subsample=None):\n",
    "    if subsample is None:\n",
    "        return data\n",
    "    pos_tensor = data[0]\n",
    "    neg_tensor = data[1]\n",
    "\n",
    "    # split the sample into half\n",
    "    half = int(subsample / 2)\n",
    "\n",
    "    pos_size = pos_tensor.shape[0]\n",
    "    neg_size = neg_tensor.shape[0]\n",
    "\n",
    "    pos_start_ind = random.randint(0, pos_size - half)\n",
    "    sample_pos = pos_tensor[pos_start_ind : (pos_start_ind + half)]\n",
    "\n",
    "    if neg_size <= half:\n",
    "        random_neg = (torch.rand(half) * neg_tensor.shape[0]).long()\n",
    "        sample_neg = torch.index_select(neg_tensor, 0, random_neg)\n",
    "    else:\n",
    "        neg_start_ind = random.randint(0, neg_size - half)\n",
    "        sample_neg = neg_tensor[neg_start_ind : (neg_start_ind + half)]\n",
    "\n",
    "    samples = torch.cat([sample_pos, sample_neg], 0)\n",
    "   # print(\"samples: \",samples)\n",
    "    randidx = torch.randperm(samples.shape[0])\n",
    "    samples = torch.index_select(samples, 0, randidx)\n",
    " #   print(\"samples(OUT): \",samples)\n",
    "    return samples\n",
    "\n",
    "def create_mesh(\n",
    "    decoder, latent_vec, filename, N=256, max_batch=(2**20), offset=None, scale=None, volume_size=2.0\n",
    "    #decoder, latent_vec, filename, N=256, max_batch=(32 ** 3 * 4), offset=None, scale=None, volume_size=2.0\n",
    "):\n",
    "    start = time.time()\n",
    "    ply_filename = filename\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-volume_size/2.0, -volume_size/2.0, -volume_size/2.0]\n",
    "#    voxel_origin = [-1.0,-1.0,-1.0]\n",
    "\n",
    "    voxel_size = volume_size / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() // N) % N\n",
    "    samples[:, 0] = ((overall_index.long() // N) // N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "    samples.requires_grad = False\n",
    "\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n",
    "        \n",
    "        samples[head : min(head + max_batch, num_samples), 3] = (\n",
    "            decode_sdf(decoder, latent_vec, sample_subset)\n",
    "            .squeeze()\n",
    "            .detach()\n",
    "            .cuda()\n",
    "        )\n",
    "        head += max_batch\n",
    "    sdf_values = samples[:, 3]\n",
    "    print(\"sdf_values\", sdf_values.min(), sdf_values.max())\n",
    "    sdf_values = sdf_values.reshape(N, N, N)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    convert_sdf_samples_to_ply(\n",
    "        sdf_values.data.cuda(),\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        ply_filename + \".ply\",\n",
    "        offset,\n",
    "        scale,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def decode_sdf(decoder, latent_vector, queries):\n",
    "    num_samples = queries.shape[0]\n",
    "\n",
    "    if latent_vector is None:\n",
    "        inputs = queries\n",
    "        sdf = decoder(inputs)[:, :1]\n",
    "    else:\n",
    "        try:\n",
    "            latent_repeat = latent_vector.expand(num_samples, -1)\n",
    "            inputs = torch.cat([latent_repeat, queries], 1)\n",
    "            with torch.no_grad():\n",
    "                sdf, p_can = decoder(inputs)\n",
    "\n",
    "        except:\n",
    "            raise RuntimeError(\"Failed to decode SDF\")\n",
    "\n",
    "    return sdf\n",
    "\n",
    "def convert_sdf_samples_to_ply(\n",
    "    input_3d_sdf_array,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    ply_filename_out,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .ply\n",
    "\n",
    "    :param input_3d_sdf_array: a float array of shape (n,n,n)\n",
    "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
    "    :voxel_size: float, the size of the voxels\n",
    "    :ply_filename_out: string, path of the filename to save to\n",
    "\n",
    "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if isinstance(input_3d_sdf_array, torch.Tensor):\n",
    "        numpy_3d_sdf_tensor = input_3d_sdf_array.cpu().numpy()\n",
    "    elif isinstance(input_3d_sdf_array, np.ndarray):\n",
    "        numpy_3d_sdf_tensor = input_3d_sdf_array\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    print(\"numpy_3d_sdf_tensor\",np.shape(numpy_3d_sdf_tensor)) #256 256 256\n",
    "    print(\"numpy_3d_sdf_tensor\",numpy_3d_sdf_tensor.min())\n",
    "    print(\"numpy_3d_sdf_tensor\",numpy_3d_sdf_tensor.max())\n",
    "    \n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3,method ='lewiner'\n",
    "    )\n",
    "\n",
    "    # transform from voxel coordinates to camera coordinates\n",
    "    # note x and y are flipped in the output of marching_cubes\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    # apply additional offset and scale\n",
    "    if scale is not None:\n",
    "        mesh_points = mesh_points / scale\n",
    "    if offset is not None:\n",
    "        mesh_points = mesh_points - offset\n",
    "\n",
    "    # try writing to the ply file\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces])\n",
    "    print(\"saving mesh to %s\" % (ply_filename_out))\n",
    "    ply_data.write(ply_filename_out)\n",
    "\n",
    "    print(\n",
    "        \"converting to ply format and writing to file took {} s\".format(\n",
    "            time.time() - start_time\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2de408d6-1647-435c-804d-97f7d60fa490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(\n",
    "    decoder,\n",
    "    num_iterations,\n",
    "    latent_size,\n",
    "    test_sdf,\n",
    "    stat,\n",
    "    clamp_dist,\n",
    "    num_samples=8000,\n",
    "    lr1=5e-4,\n",
    "    l2reg=False,\n",
    "):\n",
    "    mul_d = 10\n",
    "  #  decoder.train()\n",
    "    if type(stat) == type(0.1):\n",
    "        latent = torch.ones(1, latent_size).normal_(mean=0, std=stat).cuda()\n",
    "    else:\n",
    "        latent = torch.normal(stat[0].detach(), stat[1].detach()).cuda() #?\n",
    "    #요것이 Latent\n",
    "    latent.requires_grad = True\n",
    "    #Latent Code Optimize!\n",
    "    optimizer = torch.optim.Adam([latent], lr=lr1)\n",
    "\n",
    "    loss_num = 0\n",
    "    loss_l1 = torch.nn.L1Loss()\n",
    "\n",
    "    decoder.eval()\n",
    "    for e in range(num_iterations):\n",
    "        sdf_data = unpack(test_sdf, num_samples).cuda()\n",
    "        xyz = sdf_data[:, 0:3]\n",
    "        sdf_gt = sdf_data[:, 3].unsqueeze(1)\n",
    "        #SDF값\n",
    "        sdf_gt = torch.clamp(sdf_gt, -clamp_dist, clamp_dist)\n",
    "    #    print(\"sdf_gt:\", min(sdf_gt), max(sdf_gt))\n",
    " \n",
    "       # adjust_learning_rate(lr, optimizer, e, mul_d, adjust_lr_every)\n",
    "        lr = lr1 * ((1 / mul_d) ** (num_iterations //  int(num_iterations / 2)))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        latent_inputs = latent.expand(num_samples, -1)\n",
    "        #latent와 xyz를 concat\n",
    "        inputs = torch.cat([latent_inputs, xyz], 1).cuda()\n",
    "        pred_sdf,_ = decoder(inputs)\n",
    "        \n",
    "        pred_sdf = torch.clamp(pred_sdf, -clamp_dist, clamp_dist)\n",
    "    #    print(\"pred_sdf:\", (pred_sdf))#, max(pred_sdf))\n",
    "    \n",
    "        #SDF 기준으로 loss값 설정\n",
    "        loss = loss_l1(pred_sdf, sdf_gt)\n",
    "        if l2reg:\n",
    "            loss += 1e-4 * torch.mean(latent.pow(2))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_num = loss.item()\n",
    "\n",
    "        if e % 50 == 0:\n",
    "            print(\"num_iterations:\",e)\n",
    "\n",
    "            print(\"loss_num: \",loss_num)\n",
    "\n",
    "\n",
    "    return loss_num, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9375a998-08e6-418d-b69a-92e671f6c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Load\n",
    "\n",
    "# initialize Network\n",
    "# If you couldn't install the easydict with pip/conda, please try this.\n",
    "# git Clone https://github.com/makinacorpus/easydict.git\n",
    "\n",
    "from easydict.easydict import EasyDict as edict \n",
    "#from easydict import EasyDict as edict \n",
    "\n",
    "lstm_args = edict()\n",
    "lstm_args.steps = 8\n",
    "lstm_args.latent_size = 256\n",
    "lstm_args.h_size = 512\n",
    "lstm_args.dim = [512, 64]\n",
    "\n",
    "#lat_vecs = torch.nn.Embedding(len(sdf_loader), lstm_args.latent_size, max_norm=1)\n",
    "\n",
    "mlp_args = edict()\n",
    "mlp_args.layers = [256,256,256,256,256]\n",
    "mlp_args.wn_layers = [0,1,2,3,4]\n",
    "mlp_args.weight_norm = True\n",
    "mlp_args.dropout_layers =[0,1,2,3,4]\n",
    "mlp_args.dropout_prob = 0.05\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "weights = torch.load(\"./Pretrained Model/weights/weight/%s/weight_latest.pt\"%class1, map_location=device)\n",
    "decoder = DIT(mlp_args, lstm_args)\n",
    "decoder.load_state_dict(weights)\n",
    "#print(model)\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "#print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87c2b388-b3f8-44b4-a00d-90a8f18d5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  ff2dbafa8d66856419fb4103277a6b93.npz\n",
      "Reconstruction:  ff2dbafa8d66856419fb4103277a6b93.npz\n",
      "Latent_Filename:  reconstruction/04256520/latent/ff2dbafa8d66856419fb4103277a6b93.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.01542795542627573\n",
      "num_iterations: 50\n",
      "loss_num:  0.015230483375489712\n",
      "num_iterations: 100\n",
      "loss_num:  0.014616066589951515\n",
      "num_iterations: 150\n",
      "loss_num:  0.014517020434141159\n",
      "num_iterations: 200\n",
      "loss_num:  0.014156900346279144\n",
      "num_iterations: 250\n",
      "loss_num:  0.01359182596206665\n",
      "num_iterations: 300\n",
      "loss_num:  0.013824302703142166\n",
      "num_iterations: 350\n",
      "loss_num:  0.01258629560470581\n",
      "num_iterations: 400\n",
      "loss_num:  0.012398652732372284\n",
      "num_iterations: 450\n",
      "loss_num:  0.011590874753892422\n",
      "num_iterations: 500\n",
      "loss_num:  0.011607492342591286\n",
      "num_iterations: 550\n",
      "loss_num:  0.011182385496795177\n",
      "num_iterations: 600\n",
      "loss_num:  0.010983720421791077\n",
      "num_iterations: 650\n",
      "loss_num:  0.011154180392622948\n",
      "num_iterations: 700\n",
      "loss_num:  0.010473532602190971\n",
      "num_iterations: 750\n",
      "loss_num:  0.010420415550470352\n",
      "Current Error Avg:  0.009925547987222672\n",
      "Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?\n",
      "sdf_values tensor(-0.0423) tensor(0.9998)\n",
      "numpy_3d_sdf_tensor (256, 256, 256)\n",
      "numpy_3d_sdf_tensor -0.04232979\n",
      "numpy_3d_sdf_tensor 0.99983233\n",
      "saving mesh to reconstruction/04256520/mesh/ff2dbafa8d66856419fb4103277a6b93.ply\n",
      "converting to ply format and writing to file took 1.1720950603485107 s\n",
      "Loading:  ff35b2519455b6577b76a7024ccebf5.npz\n",
      "Reconstruction:  ff35b2519455b6577b76a7024ccebf5.npz\n",
      "Latent_Filename:  reconstruction/04256520/latent/ff35b2519455b6577b76a7024ccebf5.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.013083088211715221\n",
      "num_iterations: 50\n",
      "loss_num:  0.013091656379401684\n",
      "num_iterations: 100\n",
      "loss_num:  0.013159195892512798\n",
      "num_iterations: 150\n",
      "loss_num:  0.013028938323259354\n",
      "num_iterations: 200\n",
      "loss_num:  0.012454471550881863\n",
      "num_iterations: 250\n",
      "loss_num:  0.012776779010891914\n",
      "num_iterations: 300\n",
      "loss_num:  0.011945092119276524\n",
      "num_iterations: 350\n",
      "loss_num:  0.012023990042507648\n",
      "num_iterations: 400\n",
      "loss_num:  0.011732279323041439\n",
      "num_iterations: 450\n",
      "loss_num:  0.011375962756574154\n",
      "num_iterations: 500\n",
      "loss_num:  0.01166235376149416\n",
      "num_iterations: 550\n",
      "loss_num:  0.011166186071932316\n",
      "num_iterations: 600\n",
      "loss_num:  0.011119536124169827\n",
      "num_iterations: 650\n",
      "loss_num:  0.011085323989391327\n",
      "num_iterations: 700\n",
      "loss_num:  0.0107793053612113\n",
      "num_iterations: 750\n",
      "loss_num:  0.00999935157597065\n",
      "Current Error Avg:  0.004913317505270243\n",
      "Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?\n",
      "sdf_values tensor(-0.0423) tensor(0.9998)\n",
      "numpy_3d_sdf_tensor (256, 256, 256)\n",
      "numpy_3d_sdf_tensor -0.0423149\n",
      "numpy_3d_sdf_tensor 0.999832\n",
      "saving mesh to reconstruction/04256520/mesh/ff35b2519455b6577b76a7024ccebf5.ply\n",
      "converting to ply format and writing to file took 1.0992624759674072 s\n",
      "Loading:  ff5aa5eb5ed4041c1ef9727a7f361b49.npz\n",
      "Reconstruction:  ff5aa5eb5ed4041c1ef9727a7f361b49.npz\n",
      "Latent_Filename:  reconstruction/04256520/latent/ff5aa5eb5ed4041c1ef9727a7f361b49.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.014906005002558231\n",
      "num_iterations: 50\n",
      "loss_num:  0.014381756074726582\n",
      "num_iterations: 100\n",
      "loss_num:  0.014106646180152893\n",
      "num_iterations: 150\n",
      "loss_num:  0.013533436693251133\n",
      "num_iterations: 200\n",
      "loss_num:  0.012731648981571198\n",
      "num_iterations: 250\n",
      "loss_num:  0.012597417458891869\n",
      "num_iterations: 300\n",
      "loss_num:  0.01233594212681055\n",
      "num_iterations: 350\n",
      "loss_num:  0.012409201823174953\n",
      "num_iterations: 400\n",
      "loss_num:  0.011556372977793217\n",
      "num_iterations: 450\n",
      "loss_num:  0.01129942387342453\n",
      "num_iterations: 500\n",
      "loss_num:  0.011262800544500351\n",
      "num_iterations: 550\n",
      "loss_num:  0.010915569961071014\n",
      "num_iterations: 600\n",
      "loss_num:  0.010243833065032959\n",
      "num_iterations: 650\n",
      "loss_num:  0.010240716859698296\n",
      "num_iterations: 700\n",
      "loss_num:  0.009675794281065464\n",
      "num_iterations: 750\n",
      "loss_num:  0.009323527105152607\n",
      "Current Error Avg:  0.002854288245240847\n",
      "Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?\n",
      "sdf_values tensor(-0.0423) tensor(0.9998)\n",
      "numpy_3d_sdf_tensor (256, 256, 256)\n",
      "numpy_3d_sdf_tensor -0.042315777\n",
      "numpy_3d_sdf_tensor 0.9998321\n",
      "saving mesh to reconstruction/04256520/mesh/ff5aa5eb5ed4041c1ef9727a7f361b49.ply\n",
      "converting to ply format and writing to file took 0.9821000099182129 s\n",
      "Loading:  ffa7680b18ede5cfedeed2a7fa983956.npz\n",
      "Reconstruction:  ffa7680b18ede5cfedeed2a7fa983956.npz\n",
      "Latent_Filename:  reconstruction/04256520/latent/ffa7680b18ede5cfedeed2a7fa983956.pth\n",
      "학습된 code를 활용하지 않는다는 의미!\n",
      "num_iterations: 0\n",
      "loss_num:  0.010590973310172558\n",
      "num_iterations: 50\n",
      "loss_num:  0.010312560014426708\n",
      "num_iterations: 100\n",
      "loss_num:  0.010332267731428146\n",
      "num_iterations: 150\n",
      "loss_num:  0.010150102898478508\n",
      "num_iterations: 200\n",
      "loss_num:  0.010466893203556538\n",
      "num_iterations: 250\n",
      "loss_num:  0.009742289781570435\n",
      "num_iterations: 300\n",
      "loss_num:  0.009748718701303005\n",
      "num_iterations: 350\n",
      "loss_num:  0.009578028693795204\n",
      "num_iterations: 400\n",
      "loss_num:  0.00945322960615158\n",
      "num_iterations: 450\n",
      "loss_num:  0.00949978455901146\n",
      "num_iterations: 500\n",
      "loss_num:  0.009148452430963516\n",
      "num_iterations: 550\n",
      "loss_num:  0.008529352024197578\n",
      "num_iterations: 600\n",
      "loss_num:  0.007778963074088097\n",
      "num_iterations: 650\n",
      "loss_num:  0.007427404634654522\n",
      "num_iterations: 700\n",
      "loss_num:  0.007126284297555685\n",
      "num_iterations: 750\n",
      "loss_num:  0.006653719116002321\n",
      "Current Error Avg:  0.0015485638286918402\n",
      "Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to decode SDF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f42f31943f2d>\u001b[0m in \u001b[0;36mdecode_sdf\u001b[0;34m(decoder, latent_vector, queries)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0msdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_can\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-49b0dc885185>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# get warped points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mp_canonical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarping_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_xyzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-74bff264f817>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mcell_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Latest state!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mrgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_st\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         return _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-005e61c98fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                     create_mesh(\n\u001b[0m\u001b[1;32m     67\u001b[0m                         \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     )                       \n",
      "\u001b[0;32m<ipython-input-43-f42f31943f2d>\u001b[0m in \u001b[0;36mcreate_mesh\u001b[0;34m(decoder, latent_vec, filename, N, max_batch, offset, scale, volume_size)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         samples[head : min(head + max_batch, num_samples), 3] = (\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mdecode_sdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-f42f31943f2d>\u001b[0m in \u001b[0;36mdecode_sdf\u001b[0;34m(decoder, latent_vector, queries)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to decode SDF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to decode SDF"
     ]
    }
   ],
   "source": [
    "iterations = 800\n",
    "latent_size = 256\n",
    "num_samples=8000\n",
    "stat = 0.01\n",
    "clamp_dist = 0.1\n",
    "lr=5e-3\n",
    "l2reg=True\n",
    "resolution = 256\n",
    "use_octree = False\n",
    "\n",
    "for ii, npz in enumerate(files_npz_test):\n",
    "#    print(npz)\n",
    "    if \"npz\" not in npz:\n",
    "        continue\n",
    "    # files_dir_test #dirs\n",
    "    print(\"Loading: \",npz)\n",
    "#    DIRECTORY_MODELS\n",
    "    npz1 = np.load(DIRECTORY_MODELS+ '/'+ npz)\n",
    "    pos_tensor = torch.from_numpy(npz1[\"pos\"])\n",
    "    neg_tensor = torch.from_numpy(npz1[\"neg\"])\n",
    "    \n",
    "    data_sdf = [pos_tensor, neg_tensor]\n",
    "\n",
    "    for k in range(repeat):\n",
    "\n",
    "        mesh_filename = os.path.join(mesh_dd, npz[:-4])\n",
    "        latent_filename = os.path.join(lat_dd, npz[:-4] + \".pth\")\n",
    "\n",
    "        print(\"Reconstruction: \", npz)\n",
    "        \n",
    "        data_sdf[0] = data_sdf[0][torch.randperm(data_sdf[0].shape[0])]\n",
    "        data_sdf[1] = data_sdf[1][torch.randperm(data_sdf[1].shape[0])]\n",
    "\n",
    "        start = time.time()\n",
    "        print(\"Latent_Filename: \", latent_filename)\n",
    "\n",
    "        if not os.path.isfile(latent_filename):\n",
    "            print(\"학습된 code를 활용하지 않는다는 의미!\")\n",
    "            loss_sum = 0\n",
    "            err, latent = reconstruct(\n",
    "                decoder,\n",
    "                int(iterations),\n",
    "                latent_size,\n",
    "                data_sdf,\n",
    "                0.01,  \n",
    "                0.1,\n",
    "                num_samples=8000,\n",
    "                lr1=5e-3,\n",
    "                l2reg=True,\n",
    "            )\n",
    "            loss_sum += err\n",
    "            print(\"Current Error Avg: \", loss_sum/(ii+1))\n",
    "            \n",
    "        if not save_latvec_only:\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                #octree를 사용한다.\n",
    "                if use_octree:\n",
    "                    create_mesh_octree(\n",
    "                        decoder, latent, mesh_filename, N=resolution, max_batch=int(2 ** 17), volume_size = 0.5, #volume_size = 0.1 > 그냥 네모가 작아질 뿐\n",
    "                        clamp_func=clamping_function\n",
    "                    )\n",
    "                #Octree를 사용하지 않는다.\n",
    "                else:\n",
    "                    print('Octree를 사용하지 않고 만든다! 여기가 오래 걸리는 거 같은데?')\n",
    "                    create_mesh(\n",
    "                        decoder, latent, mesh_filename, N=resolution, max_batch=int(2 ** 17),\n",
    "                    )                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3ce3310-62f3-4a8a-858c-af4a8721113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10c7cdfdffe2243b88a89a28f04ce622.npz',\n",
       " '17ac3afd54143b797172a40a4ca640fe.npz',\n",
       " '17ad3ab1b1d12a7db26dc8ec64d633df.npz',\n",
       " '17c86b46990b54b65578b8865797aa0.npz',\n",
       " '18d123aaef6b911954eefcdc602d4520.npz',\n",
       " '18e86ba0172154f3bc0909d98a1ff2b4.npz',\n",
       " '1bba3fb413b93890947bbeb9022263b8.npz',\n",
       " '1beb0776148870d4c511571426f8b16d.npz',\n",
       " '1c93b0eb9c313f5d9a6e43b878d5b335.npz',\n",
       " '1d09583e9236b8d149d860a48be37092.npz',\n",
       " '1d0c128592385580e2129f6359ec27e3.npz',\n",
       " '1d5708929a4ae05842d1180c659735fe.npz',\n",
       " '1eb3af39d93c8bf2ddea2f4a0e0f0d2e.npz',\n",
       " '1fc2625479e798b11944f01d3ab2091b.npz',\n",
       " '24bdf389877fb7f21b1f694e36340ebb.npz',\n",
       " '24c2cc372c63603137678474be485ca.npz',\n",
       " '24d4c063f7a361bacbc6ff5546f4ec42.npz',\n",
       " '29b92db18649b64e959a8a7d5a8a5077.npz',\n",
       " '2a06adfb446c85c9f9d3f977c7090b2a.npz',\n",
       " '2a2caad9e540dcc687bf26680c510802.npz',\n",
       " '2a801b1918ef23f1121ca0b13e917b22.npz',\n",
       " '2af04ef09d49221b85e5214b0d6a7.npz',\n",
       " '2bc0d99cba39f7adbbf3143b1cb6076a.npz',\n",
       " '2c1f66380af03e4c5d1df55cbe0874aa.npz',\n",
       " '2d43c1430df8194ace5721ccacba16.npz',\n",
       " '2d4a57a467307d675e9e2656aff7dd5b.npz',\n",
       " '33d955301966e4215ebedace13b486c4.npz',\n",
       " '34ddff243ac3783521b85e5214b0d6a7.npz',\n",
       " '38a8e07ed9b0da99fa7918e5874b2c16.npz',\n",
       " '39d7e8e001e0234e8f721bc8b8155d7.npz',\n",
       " '3a18489f9615a350e768735f27170bc4.npz',\n",
       " '3a3827f1a76c5230e24527abcb488f31.npz',\n",
       " '3a82056ea319a442f64801ad2940cdd5.npz',\n",
       " '3b2a19d782234467f9cc1fc25372199f.npz',\n",
       " '3c80dde1fb615ff5ca8607f540cc62ba.npz',\n",
       " '3c9d577c78dcc3904c3a35cee92bb95b.npz',\n",
       " '3cab1ffcff8b84cbcad035c2ab458.npz',\n",
       " '3cb63efff711cfc035fc197bbabcd5bd.npz',\n",
       " '3fd97395c1d1479b35cfde72d9f6a4cf.npz',\n",
       " '3fe365251b54087af0478431b5ad57db.npz',\n",
       " '40c730231c4da8f33c3bcafb5ffed4c0.npz',\n",
       " '43abe330362164e99be82ec29531a70f.npz',\n",
       " '43c5f85e9a10071cb1bb46d2556ba67d.npz',\n",
       " '46c259e87609c54fafc0cc47720c0ef4.npz',\n",
       " '46d4d453ceac2f5c3c3b254d8683a766.npz',\n",
       " '47d677bf1dec3dca82cea33798fcd6b6.npz',\n",
       " '48d03ffabd0399f4303510f9a56d94fe.npz',\n",
       " '4a27a6276e748777bc0909d98a1ff2b4.npz',\n",
       " '4a300ea7cbe3ae58a42c49797afd1f5c.npz',\n",
       " '4a552066ae1da546cc34b900bb2492e.npz',\n",
       " '4b4fd540cab0cdf3f38bce64a8733419.npz',\n",
       " '4bd5f77521e76e6a2e690fa6dfd5d610.npz',\n",
       " '4bf2c942aafb4a2cbd46d022fd7d80aa.npz',\n",
       " '4bfa5d948d9ca7ab7c5f0032facde6fe.npz',\n",
       " '4c008f39378be18bc0909d98a1ff2b4.npz',\n",
       " '4d50ff789e84e70e54eefcdc602d4520.npz',\n",
       " '4eced94670d10b35e856faf938562bd0.npz',\n",
       " '4f1fb7c062c50fb15a2c5766752aea65.npz',\n",
       " '4f9b12d07dce21ac9d93a50cb0355558.npz',\n",
       " '4fb69651d04e010554eefcdc602d4520.npz',\n",
       " '5c63ad3688c623b1a787d03c28977672.npz',\n",
       " '5d925e4748bb4ad155050237670e0ad2.npz',\n",
       " '5da145252e095024ee738cc95b5ae8e.npz',\n",
       " '5e31a194b02a286df8c6d04d97f8cf7.npz',\n",
       " '6ad89740605331aef5f09964a6a1f97.npz',\n",
       " '6ba7cad8fa7301f9c1ca96a73599ca7e.npz',\n",
       " '6bfee98d2078c3c4ca8607f540cc62ba.npz',\n",
       " '6cd3028fe03d04fec6f6da58b133bae0.npz',\n",
       " '6cdc9acb022b2d7d98aeb62a3dfc01d8.npz',\n",
       " '6cf339eb8c950ac5d556fc099c90ab45.npz',\n",
       " '6d0b546bb6256eb5e66cabd11ba41eae.npz',\n",
       " '6d93492543d1087eb87697d3904b168b.npz',\n",
       " '6dedeb5b87ee318b2154ead1f7ab03aa.npz',\n",
       " '6ea4e68428cba49f68557927e45c29cd.npz',\n",
       " '6eb12144093da25e816e98a113f4d393.npz',\n",
       " '6ed172205a9805b8dd9eb6c0ee8316a3.npz',\n",
       " '6f96517661cf1b6799ed03445864bd37.npz',\n",
       " '6feb039c710277aabd10f71f04d299c.npz',\n",
       " '7a1954799b5fbb438fc2d09ac4aa4e78.npz',\n",
       " '7a97d3dadc608b4350f01eb2b12b0a8.npz',\n",
       " '7bd43965f17c25377209009cfb89d4bd.npz',\n",
       " '7c67e8cce3f3eb3c89ba278a735b3c5a.npz',\n",
       " '7e52ac52a2eb74ac26360e1e29a956c7.npz',\n",
       " '7ea57db538494a2fc1ccec171a275967.npz',\n",
       " '7ecb807e2270606619ba010ddb4974fe.npz',\n",
       " '7ee59463dc17ac6e3e3f3c9608255377.npz',\n",
       " '7f1eaf37fb4e24de82cea33798fcd6b6.npz',\n",
       " '7f6af37cd64377e1cabcecce1c335df1.npz',\n",
       " '8af46946b9b2b3aacf0820a704ed425d.npz',\n",
       " '8bde5a00c3caf9771d03b466c72ce41.npz',\n",
       " '8ef4637cb349584420c6a28228acb628.npz',\n",
       " '8f39d2dbb98bce6057b643a522b3d830.npz',\n",
       " '8fc553e3a88b7ad54e461d462a3ccbc4.npz',\n",
       " '9bf3c126d5918c41f5c7319b71bdce6e.npz',\n",
       " '9c7395d87c59aa54a79f2ed56427c6e6.npz',\n",
       " '9c9d6469ecdfc54fc2a9d7232db0ed61.npz',\n",
       " '9cda097e69ef82beace5721ccacba16.npz',\n",
       " '9dbab9e46b372e837645a27090729af6.npz',\n",
       " '9e30fc9f2d9ae56e3ec83bd6bef75c92.npz',\n",
       " '9f75309b9744f1b54eefcdc602d4520.npz']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_npz_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3bb26-cfa7-4f4d-afd2-7c66473dae0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8df61-5387-4053-b8aa-5f2a923320d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f13f3-2741-4484-afb8-aa9f96eae5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adc62b-b55a-40e8-a76b-2d9593cae656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
